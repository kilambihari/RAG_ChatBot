# ğŸ§  Agentic RAG Chatbot (Gemini + MCP)

A multi-agent **Retrieval-Augmented Generation (RAG)** chatbot powered by **Gemini (pro/flash)** and **Model Context Protocol (MCP)**. It allows users to upload documents, intelligently parse them, retrieve relevant content, and generate answers using an LLMâ€”all with agentic communication.

## ğŸš€ Features

ğŸ“„ Multi-format Document Upload: Supports PDF, DOCX, TXT, PPTX, CSV, MD for ingestion

ğŸ¤– Agent-based Architecture: Built with Model Context Protocol (MCP) to facilitate modular communication

ğŸ” Semantic Search: Uses Gemini Embeddings + FAISS vector store for fast, relevant retrieval

ğŸ’¬ LLM-Powered Chatbot: Natural language Q&A via Gemini Pro or Gemini 1.5 Flash

ğŸ§© Modular Agents:

IngestionAgent: Parses and chunks documents

RetrievalAgent: Retrieves relevant content using vector similarity

LLMResponseAgent: Generates human-like answers using Gemini LLMs

ğŸŒ Deployable via Streamlit Cloud: Fully web-based, no local setup required

âœ… Gemini API Ready: Easily switch between gemini-pro or gemini-1.5-flash

---

## ğŸ§± Architecture

```bash
ğŸ“ rag_chatbot/
â”œâ”€â”€ app.py
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ ingestion_agent.py
â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â””â”€â”€ llm_response_agent.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ parser.py
â”‚   â”œâ”€â”€ embedding.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â””â”€â”€ mcp.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


## ğŸš€ Live Demo

ğŸ”— **Streamlit App**: [Click here to view the RAG Chatbot](https://ragchatbot-peybjfbeevhbbhx4x4dmqo.streamlit.app/)
